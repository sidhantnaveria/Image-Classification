{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=\"data/data/\"\n",
    "category=[\"healthyfood\",\"junkfood\"]\n",
    "\n",
    "def save(X,y,x_test,y_test):\n",
    "    pickle_out = open(\"X.pickle\",\"wb\")\n",
    "    pickle.dump(X, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(\"x_test.pickle\",\"wb\")\n",
    "    pickle.dump(x_test, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(\"y.pickle\",\"wb\")\n",
    "    pickle.dump(y, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(\"y_test.pickle\",\"wb\")\n",
    "    pickle.dump(y_test, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "def load():\n",
    "    pickle_in = open(\"X.pickle\",\"rb\")\n",
    "    X = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(\"x_test.pickle\",\"rb\")\n",
    "    x_test = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(\"y.pickle\",\"rb\")\n",
    "    y = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(\"y_test.pickle\",\"rb\")\n",
    "    y_test = pickle.load(pickle_in)\n",
    "    return X,x_test,y,y_test\n",
    "def data_set():\n",
    "    \n",
    "    #IMG_SIZE=256\n",
    "    data=[]\n",
    "    \n",
    "    for cat in category:  # do dogs and cats\n",
    "        path = os.path.join(dataDir,cat)\n",
    "        class_num=category.index(cat)\n",
    "        for img in os.listdir(path):\n",
    "            \n",
    "        # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                \n",
    "                img_array = cv2.imread(os.path.join(path,img) )  # convert to array\n",
    "                new_array = cv2.resize(img_array, (255, 255))  # resize to normalize data size\n",
    "                data.append([new_array, class_num])\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                    pass\n",
    "                \n",
    "    \n",
    "    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    X=[]\n",
    "    y=[] \n",
    "    for features,label in data:\n",
    "        X.append(features)\n",
    "        y.append(label)         \n",
    "    X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2)\n",
    "    \n",
    "    \n",
    "    X_train = np.array(X_train).reshape(-1, 255, 255, 3)\n",
    "    X_test = np.array(X_test).reshape(-1, 255, 255, 3)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    X_train = X_train/255.0\n",
    "    X_test=X_test/255.0\n",
    "    \n",
    "    save(X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set()\n",
    "def load():\n",
    "    pickle_in = open(\"X.pickle\",\"rb\")\n",
    "    X = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(\"x_test.pickle\",\"rb\")\n",
    "    x_test = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(\"y.pickle\",\"rb\")\n",
    "    y = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(\"y_test.pickle\",\"rb\")\n",
    "    y_test = pickle.load(pickle_in)\n",
    "    return X,x_test,y,y_test\n",
    "X_train,X_test,y_train,y_test=load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (1, 1), input_shape=X_train.shape[1:]))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (1, 2)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Conv2D(64, (2, 1)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (2, 2)))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 2),kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 3)))\n",
    "model.add(Conv2D(128, (2, 3),kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3, 2)))\n",
    "model.add(Conv2D(256, (3, 3),kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(1024,kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024,kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512,kernel_regularizer=l2(0.00005), bias_regularizer=l2(0.00005)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer=optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False),metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "#predout = np.argmax(predicts)\n",
    "#testout = np.argmax(y_test)\n",
    "#\n",
    "#\n",
    "#testScores = metrics.accuracy_score(y_test,predicts)\n",
    "#confusion = metrics.confusion_matrix(testout,predout)\n",
    "#print(result)\n",
    "#print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "bs=4\n",
    "epoch=40\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "H = model.fit_generator(aug.flow(X_train, y_train, batch_size=bs),\n",
    "\t steps_per_epoch=len(X_train),\n",
    "\tepochs=epoch)\n",
    "model.save_weights('my_model_weights.h5')\n",
    "bs=8\n",
    "epoch=100\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
    "model.load_weights('my_model_weights.h5')\n",
    "H = model.fit_generator(aug.flow(X_train, y_train, batch_size=bs),\n",
    "\t steps_per_epoch=len(X_train),\n",
    "\tepochs=epoch)\n",
    "model.save_weights('my_model_weights.h5')\n",
    "bs=16\n",
    "epoch=60\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.load_weights('my_model_weights.h5')\n",
    "H = model.fit_generator(aug.flow(X_train, y_train, batch_size=bs),\n",
    "\t steps_per_epoch=len(X_train),\n",
    "\tepochs=epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_acc)\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(H.history['loss'], label='train')\n",
    "#plt.plot(H.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(H.history['acc'], label='train')\n",
    "#plt.plot(H.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
